{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361cca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator, BranchPythonOperator\n",
    "from airflow.providers.postgres.operators.postgres import PostgresOperator\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.providers.http.hooks.http import HttpHook\n",
    "\n",
    "http_conn_id = HttpHook.get_connection('http_conn_id')\n",
    "api_key = http_conn_id.extra_dejson.get('api_key')\n",
    "base_url = http_conn_id.host\n",
    "\n",
    "print ('base_url  ', base_url, 'api_key ', api_key)\n",
    "\n",
    "postgres_conn_id = 'postgresql_de'\n",
    "\n",
    "nickname = 'Ilya'\n",
    "cohort = '23'\n",
    "\n",
    "headers = {\n",
    "    'X-Nickname': nickname,\n",
    "    'X-Cohort': cohort,\n",
    "    'X-Project': 'True',\n",
    "    'X-API-KEY': api_key,\n",
    "    'Content-Type': 'application/x-www-form-urlencoded'\n",
    "}\n",
    "\n",
    "#Метод /generate_report инициализирует формирование отчёта\n",
    "def generate_report(ti):\n",
    "    print('Making request generate_report')\n",
    "\n",
    "    response = requests.post(f'{base_url}/generate_report', headers=headers)\n",
    "    response.raise_for_status()\n",
    "    task_id = json.loads(response.content)['task_id']\n",
    "    ti.xcom_push(key='task_id', value=task_id)\n",
    "    print(f'Response is {response.content}')\n",
    "    print(f'task_id: {task_id}')\n",
    "\n",
    "#Метод get_report используется для получения отчёта после того, как он будет сформирован на сервере.\n",
    "def get_report(ti):\n",
    "    print('Making request get_report')\n",
    "    task_id = ti.xcom_pull(key='task_id')\n",
    "\n",
    "    report_id = None\n",
    "\n",
    "    for i in range(20):\n",
    "        response = requests.get(f'{base_url}/get_report?task_id={task_id}', headers=headers)\n",
    "        response.raise_for_status()\n",
    "        print(f'Response is {response.content}')\n",
    "        status = json.loads(response.content)['status']\n",
    "        if status == 'SUCCESS':\n",
    "            report_id = json.loads(response.content)['data']['report_id']\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(10)\n",
    "\n",
    "    if not report_id:\n",
    "        raise TimeoutError()\n",
    "\n",
    "    ti.xcom_push(key='report_id', value=report_id)\n",
    "    print(f'Report_id={report_id}')\n",
    "\n",
    "#Метод get_increment используется для получения данных за те даты, которые не вошли в основной отчёт\n",
    "def get_increment(date, ti):\n",
    "    print('Making request get_increment')\n",
    "    report_id = ti.xcom_pull(key='report_id')\n",
    "    response = requests.get(\n",
    "        f'{base_url}/get_increment?report_id={report_id}&date={str(date)}T00:00:00',\n",
    "        headers=headers)\n",
    "    response.raise_for_status()\n",
    "    print(f'Response is {response.content}')\n",
    "\n",
    "    increment_id = json.loads(response.content)['data']['increment_id']\n",
    "    if not increment_id:\n",
    "        raise ValueError(f'Increment is empty. Most probably due to error in API call.')\n",
    "    \n",
    "    ti.xcom_push(key='increment_id', value=increment_id)\n",
    "    print(f'increment_id={increment_id}')\n",
    "\n",
    "#функционал отмены заказов и возврата средств (refunded)\n",
    "def upload_data_to_staging(filename, date, pg_table, pg_schema, ti):\n",
    "    increment_id = ti.xcom_pull(key='increment_id')\n",
    "    s3_filename = f'https://storage.yandexcloud.net/s3-sprint3/cohort_{cohort}/{nickname}/project/{increment_id}/{filename}'\n",
    "    print(s3_filename)\n",
    "    local_filename = date.replace('-', '') + '_' + filename\n",
    "    print(local_filename)\n",
    "    response = requests.get(s3_filename)\n",
    "    response.raise_for_status()\n",
    "    open(f\"{local_filename}\", \"wb\").write(response.content)\n",
    "    print(response.content)\n",
    "\n",
    "    df = pd.read_csv(local_filename)\n",
    "    df=df.drop('id', axis=1)\n",
    "    df=df.drop_duplicates(subset=['uniq_id'])\n",
    "\n",
    "    if 'status' not in df.columns:\n",
    "        df['status'] = 'shipped'\n",
    "\n",
    "    postgres_hook = PostgresHook(postgres_conn_id)\n",
    "    engine = postgres_hook.get_sqlalchemy_engine()\n",
    "    row_count = df.to_sql(pg_table, engine, schema=pg_schema, if_exists='append', index=False)\n",
    "    print(f'{row_count} rows was inserted')\n",
    "\n",
    "\n",
    "args = {\n",
    "    \"owner\": \"student\",\n",
    "    'email': ['student@example.com'],\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 0\n",
    "}\n",
    "\n",
    "business_dt = '{{ ds }}'\n",
    "\n",
    "with DAG(\n",
    "        'sales_mart',\n",
    "        default_args=args,\n",
    "        description='Provide default dag for sprint3',\n",
    "        catchup=True,\n",
    "        start_date=datetime.today() - timedelta(days=7),\n",
    "        end_date=datetime.today() - timedelta(days=1),\n",
    ") as dag:\n",
    "    generate_report = PythonOperator(\n",
    "        task_id='generate_report',\n",
    "        python_callable=generate_report)\n",
    "\n",
    "    get_report = PythonOperator(\n",
    "        task_id='get_report',\n",
    "        python_callable=get_report)\n",
    "\n",
    "    get_increment = PythonOperator(\n",
    "        task_id='get_increment',\n",
    "        python_callable=get_increment,\n",
    "        op_kwargs={'date': business_dt})\n",
    "    \n",
    "    #добавим колонку статус в таблицу staging.user_order_log\n",
    "    #status_user_order_log = PostgresOperator(\n",
    "    #    task_id='status_user_order_log',\n",
    "    #    postgres_conn_id=postgres_conn_id,\n",
    "    #    sql=\"sql/status.user_order_log.sql\")\n",
    "\n",
    "    upload_user_order_inc = PythonOperator(\n",
    "        task_id='upload_user_order_inc',\n",
    "        python_callable=upload_data_to_staging,\n",
    "        op_kwargs={'date': business_dt,\n",
    "                   'filename': 'user_order_log_inc.csv',\n",
    "                   'pg_table': 'user_order_log',\n",
    "                   'pg_schema': 'staging'})\n",
    "\n",
    "    update_d_item_table = PostgresOperator(\n",
    "        task_id='update_d_item',\n",
    "        postgres_conn_id=postgres_conn_id,\n",
    "        sql=\"sql/mart.d_item.sql\")\n",
    "\n",
    "    update_d_customer_table = PostgresOperator(\n",
    "        task_id='update_d_customer',\n",
    "        postgres_conn_id=postgres_conn_id,\n",
    "        sql=\"sql/mart.d_customer.sql\")\n",
    "\n",
    "    update_d_city_table = PostgresOperator(\n",
    "        task_id='update_d_city',\n",
    "        postgres_conn_id=postgres_conn_id,\n",
    "        sql=\"sql/mart.d_city.sql\")\n",
    "\n",
    "    update_f_sales = PostgresOperator(\n",
    "        task_id='update_f_sales',\n",
    "        postgres_conn_id=postgres_conn_id,\n",
    "        sql=\"sql/mart.f_sales.sql\",\n",
    "        parameters={\"date\": {business_dt}}\n",
    "    )\n",
    "\n",
    "    (\n",
    "            generate_report\n",
    "            >> get_report\n",
    "            >> get_increment\n",
    "            >> upload_user_order_inc\n",
    "            >> [update_d_item_table, update_d_city_table, update_d_customer_table]\n",
    "            >> update_f_sales\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
